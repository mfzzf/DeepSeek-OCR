# DeepSeek-OCR Docker æ„å»ºå’Œä½¿ç”¨æŒ‡å—

## ğŸ“‹ å‰ææ¡ä»¶

- Docker å·²å®‰è£…
- NVIDIA Docker runtime å·²é…ç½®
- CUDA 12.1/12.2 é©±åŠ¨
- GPU æ˜¾å­˜ >= 16GB (æ¨è 24GB+)

## ğŸš€ å¿«é€Ÿå¼€å§‹

### æ–¹æ³• 1: ä½¿ç”¨ Docker Compose (æ¨è)

```bash
# 1. æ„å»ºé•œåƒ
docker-compose build

# 2. å¯åŠ¨æœåŠ¡
docker-compose up -d

# 3. æŸ¥çœ‹æ—¥å¿—
docker-compose logs -f

# 4. åœæ­¢æœåŠ¡
docker-compose down
```

### æ–¹æ³• 2: ä½¿ç”¨ Docker å‘½ä»¤

```bash
# 1. æ„å»ºé•œåƒ
docker build -t deepseek-ocr-vllm:latest .

# 2. è¿è¡Œå®¹å™¨
docker run -d \
  --name deepseek-ocr-api \
  --gpus all \
  --shm-size 8g \
  -p 8000:8000 \
  -v $(pwd)/DeepSeek-OCR-vllm/models:/app/models:ro \
  -e LOG_LEVEL=INFO \
  -e VLLM_USE_V1=1 \
  deepseek-ocr-vllm:latest

# 3. æŸ¥çœ‹æ—¥å¿—
docker logs -f deepseek-ocr-api

# 4. åœæ­¢å®¹å™¨
docker stop deepseek-ocr-api
docker rm deepseek-ocr-api
```

## ğŸ”§ é…ç½®é€‰é¡¹

### ç¯å¢ƒå˜é‡

- `HOST`: æœåŠ¡ç»‘å®šåœ°å€ (é»˜è®¤: 0.0.0.0)
- `PORT`: æœåŠ¡ç«¯å£ (é»˜è®¤: 8000)
- `WORKERS`: Worker æ•°é‡ (é»˜è®¤: 1)
- `LOG_LEVEL`: æ—¥å¿—çº§åˆ« INFO/DEBUG (é»˜è®¤: INFO)
- `VLLM_USE_V1`: ä½¿ç”¨ vLLM V1 å¼•æ“ (é»˜è®¤: 1)
- `CUDA_VISIBLE_DEVICES`: æŒ‡å®š GPU (é»˜è®¤: 0)

### å¯ç”¨è°ƒè¯•æ—¥å¿—

```bash
docker run -d \
  --name deepseek-ocr-api \
  --gpus all \
  --shm-size 8g \
  -p 8000:8000 \
  -v $(pwd)/DeepSeek-OCR-vllm/models:/app/models:ro \
  -e LOG_LEVEL=DEBUG \
  deepseek-ocr-vllm:latest
```

### æŒ‡å®š GPU

```bash
# ä½¿ç”¨ç‰¹å®š GPU
docker run -d \
  --gpus '"device=0"' \
  -e CUDA_VISIBLE_DEVICES=0 \
  ...

# ä½¿ç”¨å¤šä¸ª GPU
docker run -d \
  --gpus '"device=0,1"' \
  -e CUDA_VISIBLE_DEVICES=0,1 \
  ...
```

## ğŸ“Š æµ‹è¯• API

### å¥åº·æ£€æŸ¥

```bash
curl http://localhost:8000/health
```

### åˆ—å‡ºæ¨¡å‹

```bash
curl http://localhost:8000/v1/models
```

### OCR è¯·æ±‚ç¤ºä¾‹

```bash
curl -X POST http://localhost:8000/v1/chat/completions \
  -H "Content-Type: application/json" \
  -d '{
    "model": "deepseek-ocr",
    "messages": [
      {
        "role": "user",
        "content": [
          {
            "type": "text",
            "text": "Convert the document to markdown."
          },
          {
            "type": "image_url",
            "image_url": {
              "url": "data:image/jpeg;base64,/9j/4AAQ..."
            }
          }
        ]
      }
    ],
    "max_tokens": 8192,
    "temperature": 0.0
  }'
```

## ğŸ” æ•…éšœæ’æŸ¥

### æŸ¥çœ‹å®¹å™¨æ—¥å¿—

```bash
# Docker Compose
docker-compose logs -f

# Docker
docker logs -f deepseek-ocr-api
```

### è¿›å…¥å®¹å™¨è°ƒè¯•

```bash
# Docker Compose
docker-compose exec deepseek-ocr-api bash

# Docker
docker exec -it deepseek-ocr-api bash
```

### æ£€æŸ¥ GPU

```bash
docker exec -it deepseek-ocr-api nvidia-smi
```

### å¸¸è§é—®é¢˜

#### 1. CUDA ç‰ˆæœ¬ä¸å…¼å®¹

**é”™è¯¯**: `cuda>=12.8, please update your driver`

**è§£å†³**: Dockerfile å·²è®¾ç½®ä¸ºä½¿ç”¨ `v0.6.3.post1` é•œåƒï¼Œå…¼å®¹ CUDA 12.1/12.2

#### 2. æ˜¾å­˜ä¸è¶³

**é”™è¯¯**: `CUDA out of memory`

**è§£å†³**: 
- å‡å°‘ `gpu_memory_utilization` (åœ¨ openai_api_server.py ä¸­ä¿®æ”¹)
- é™ä½ `MAX_CROPS` (åœ¨ config.py ä¸­ä¿®æ”¹)
- ä½¿ç”¨æ›´å¤§æ˜¾å­˜çš„ GPU

#### 3. æ¨¡å‹åŠ è½½å¤±è´¥

**é”™è¯¯**: `Model not found`

**è§£å†³**: ç¡®ä¿æ¨¡å‹æ–‡ä»¶å·²æ­£ç¡®æŒ‚è½½åˆ°å®¹å™¨ä¸­
```bash
ls -la ./DeepSeek-OCR-vllm/models/
```

## ğŸ“¦ é•œåƒä¿¡æ¯

- **åŸºç¡€é•œåƒ**: vllm/vllm-openai:v0.6.3.post1
- **CUDA æ”¯æŒ**: 12.1/12.2
- **Python**: 3.10+
- **é¢„è£…ç»„ä»¶**: PyTorch, vLLM, FastAPI, Uvicorn

## ğŸ”„ æ›´æ–°é•œåƒ

```bash
# é‡æ–°æ„å»º
docker-compose build --no-cache

# æˆ–
docker build --no-cache -t deepseek-ocr-vllm:latest .
```

## ğŸ“ ç”Ÿäº§ç¯å¢ƒå»ºè®®

1. ä½¿ç”¨ç‰¹å®šç‰ˆæœ¬æ ‡ç­¾è€Œä¸æ˜¯ `latest`
2. é…ç½®èµ„æºé™åˆ¶ (CPU/å†…å­˜)
3. è®¾ç½®é€‚å½“çš„é‡å¯ç­–ç•¥
4. é…ç½®æ—¥å¿—è½®è½¬
5. ä½¿ç”¨åå‘ä»£ç† (Nginx/Traefik)
6. å¯ç”¨ HTTPS
7. é…ç½®ç›‘æ§å’Œå‘Šè­¦

## ğŸŒ ç½‘ç»œé…ç½®

å¦‚æœéœ€è¦åœ¨å…¶ä»–æœºå™¨è®¿é—®ï¼Œç¡®ä¿é˜²ç«å¢™å·²å¼€æ”¾ç«¯å£ï¼š

```bash
# Ubuntu/Debian
sudo ufw allow 8000

# CentOS/RHEL
sudo firewall-cmd --permanent --add-port=8000/tcp
sudo firewall-cmd --reload
```

